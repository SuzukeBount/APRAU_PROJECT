Support Vector Machines ou SVMs, são modelos de machine learning utilizado, tanto para exercícios de regressão, como de classificação
O objetivo principal de um SVM é encontrar o melhor plano de decissão que separa os diferentes data point, em distantas classes, são mai eficientes em espaços de maior dimensão

O principal objetivo de um SVM classifier, ou SVC, é encontrar o hiperplano que maximiza a margem entre duas classes da data, sendo a margem a distância entre o hiperplano e o data point mais pert de cada classe
Este data points são os chamados de support vectos, pois estes estão diretamente sob influência do limite de decissão


Aquilo que foi pedido para o trabalho, foram 3 principais a hora de testar e analisar SVCs

1. Testar todos os kernels possíveis
    - Linear: é maiormente utilizado quando o numero de features é grande quando comprada com o número de amostras, ou quando a data é linearmente separável
    - RBF: é utilizado em problemas não lineares, sendo este o kernel default do SVC
    - Poly: são utilizados perante problemas polinomiais dentro do dataset
    - Sigmoid: utiliza-se sigmois quando estamos perante redes neuronais e quando sabemos que a distribução da data, refere a uma função Sigmoid

Para cada um destes kernels, foi corrido cada modelo, para poder comprar-los:


Accuracy with linear kernel: 0.8038

Mean Squared Error (MSE): 0.2983
Mean Absolute Error (MAE): 0.2302
Root Mean Squared Error (RMSE): 0.5461
Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.59      0.67       424
           1       0.77      0.90      0.83       569
           2       0.92      0.93      0.92       271

    accuracy                           0.80      1264
   macro avg       0.82      0.81      0.81      1264
weighted avg       0.80      0.80      0.80      1264

Confusion Matrix:
[[251 150  23]
 [ 55 514   0]
 [ 20   0 251]]

Accuracy with rbf kernel: 0.7674
Mean Squared Error (MSE): 0.3536
Mean Absolute Error (MAE): 0.2729
Root Mean Squared Error (RMSE): 0.5947
Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.46      0.57       424
           1       0.72      0.93      0.81       569
           2       0.89      0.92      0.91       271

    accuracy                           0.77      1264
   macro avg       0.79      0.77      0.76      1264
weighted avg       0.77      0.77      0.75      1264

Confusion Matrix:
[[194 200  30]
 [ 42 527   0]
 [ 21   1 249]]

Accuracy with poly kernel: 0.7271
Mean Squared Error (MSE): 0.4082
Mean Absolute Error (MAE): 0.3180
Root Mean Squared Error (RMSE): 0.6389
Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.32      0.45       424
           1       0.67      0.96      0.79       569
           2       0.87      0.89      0.88       271

    accuracy                           0.73      1264
   macro avg       0.76      0.72      0.70      1264
weighted avg       0.74      0.73      0.69      1264

Confusion Matrix:
[[135 253  36]
 [ 25 544   0]
 [ 21  10 240]]

Accuracy with sigmoid kernel: 0.4866
Mean Squared Error (MSE): 0.7152
Mean Absolute Error (MAE): 0.5807
Root Mean Squared Error (RMSE): 0.8457
Classification Report:
              precision    recall  f1-score   support

           0       0.48      0.51      0.49       424
           1       0.50      0.70      0.58       569
           2       0.00      0.00      0.00       271

    accuracy                           0.49      1264
   macro avg       0.33      0.40      0.36      1264
weighted avg       0.39      0.49      0.43      1264

Confusion Matrix:
[[218 192  14]
 [169 397   3]
 [ 71 200   0]]

Inicialmente, o melhor kernel para o medelo será o linear, também contendo o menor erro de todos. Tendo também, o melhor precision, recall e f1 ao longo dos kernerls apresentados
Sendo o Linear o melhor kernel, quando não exitem outros atributos presentes no modelo SVC


Ao analisar cada um dos parámetros de validação, o melhor kernel para o modelo, será o RBF, seguido do Polinomial, e em ultimo Linear e sigmoid

2. Utilizar o método de Grid Search para encontrar os melhores parámetros para cada kernel
        
        # Initialize SVM with the specified kernel
        svm = SVC(kernel=kernel, random_state=42)

        # Define parameter grid for GridSearchCV
        param_grid = {
            'C': [0.1, 1],
            'degree': [2, 3, 4],
            'gamma': ['scale', 'auto', 0.01],
            'coef0': [0.0, 0.1, 1.0],
            'shrinking': [True, False],
            'probability': [True, False],
            'tol': [0.001, 0.1],
            'cache_size': [200, 500],
            'class_weight': [None, 'balanced'],
            'verbose': [False],
            'max_iter': [2000],
            'decision_function_shape': ['ovr', 'ovo'],
            'break_ties': [True, False]
        }
        
        # Perform GridSearchCV to find the best parameters
        grid_search = GridSearchCV(svm, param_grid, cv=3, verbose=1, n_jobs=-1)
        grid_search.fit(X_train, y_train)
        
        # Get the best estimator
Para cada um dos kernels utilizados, será necessário fazer um Grid Search, que procure os melhores valores para cada um dos atributos do modelo
Devido a limitações têcnicas e de poder de computação, foram escolhidas num param_grid, 2 ou 3 valores para cada atributo, sendo que as máquinas que nós temos, não têm o poder de computação necessário para lidar com procuras
de mais do que 40-50 mil procuras
Sendo asssim também que a cross validation utilizada, foi de 3 e não de 5 ou 10
Embora limitado, os resultados obtidos, são úteis para análise, sendo que existem valores que efetivamente, variam de kernel a kernel
Estes foram os resultados para cada kernel em ordem

- Linear
{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 
'degree': 2, 'gamma': 'scale', 'max_iter': 1000, 'probability': True, 'shrinking': True, 'tol': 0.001, 'verbose': False}
- RBF
{'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 
'degree': 2, 'gamma': 'scale', 'max_iter': 2000, 'probability': True, 'shrinking': True, 'tol': 0.1, 'verbose': False}
- Poly
{'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': 'balanced', 'coef0': 1.0, 'decision_function_shape': 
'ovr', 'degree': 4, 'gamma': 'scale', 'max_iter': 2000, 'probability': True, 'shrinking': True, 'tol': 0.1, 'verbose': False}
- Sigmoid
{'C': 0.1, 'break_ties': True, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 
'ovr', 'degree': 2, 'gamma': 'auto', 'max_iter': 2000, 'probability': True, 'shrinking': True, 'tol': 0.001, 'verbose': False}



3. Analisar os resultados e tirar conclussões
Finalmente, com estes valores dos atributos para cada um dos kernels utilizados, podemos fazer um modelo completo, para assim, ter a melhor performance possível para cada kernel
Estes foram os resultados obtidos:

Accuracy with linear kernel: 0.7002
Mean Squared Error (MSE): 0.5419
Mean Absolute Error (MAE): 0.3805
Root Mean Squared Error (RMSE): 0.7362
Classification Report:
              precision    recall  f1-score   support

           0       0.57      0.50      0.53       424
           1       0.72      0.83      0.77       569
           2       0.84      0.74      0.79       271

    accuracy                           0.70      1264
   macro avg       0.71      0.69      0.70      1264
weighted avg       0.70      0.70      0.69      1264

Confusion Matrix:
[[210 175  39]
 [ 95 474   0]
 [ 63   7 201]]

Accuracy with rbf kernel: 0.7674
Mean Squared Error (MSE): 0.3513
Mean Absolute Error (MAE): 0.2722
Root Mean Squared Error (RMSE): 0.5927
Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.46      0.57       424
           1       0.72      0.93      0.81       569
           2       0.89      0.92      0.91       271

    accuracy                           0.77      1264
   macro avg       0.79      0.77      0.76      1264
weighted avg       0.77      0.77      0.75      1264

Confusion Matrix:
[[194 200  30]
 [ 42 527   0]
 [ 20   2 249]]

Accuracy with poly kernel: 0.6677
Mean Squared Error (MSE): 0.3964
Mean Absolute Error (MAE): 0.3536
Root Mean Squared Error (RMSE): 0.6296
Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.68      0.58       424
           1       0.72      0.51      0.59       569
           2       0.92      0.99      0.95       271

    accuracy                           0.67      1264
   macro avg       0.71      0.72      0.71      1264
weighted avg       0.69      0.67      0.67      1264

Confusion Matrix:
[[289 112  23]
 [281 288   0]
 [  4   0 267]]
Accuracy with sigmoid kernel: 0.4502

Mean Squared Error (MSE): 0.5498
Mean Absolute Error (MAE): 0.5498
Root Mean Squared Error (RMSE): 0.7415
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       424
           1       0.45      1.00      0.62       569
           2       0.00      0.00      0.00       271

    accuracy                           0.45      1264
   macro avg       0.15      0.33      0.21      1264
weighted avg       0.20      0.45      0.28      1264

Confusion Matrix:
[[  0 424   0]
 [  0 569   0]
 [  0 271   0]]

 Analissando os resultados obtidos depois de ter acrescentado os atributos para cada kernel, podemos tirar várias conclussões
 
1. A classe 0 é a mais complicada de classificar, sendo a que menor precision, recall e f1-score tem

2. O melhor kernel com os atributos adicionados, é o RBF, sendo o que melhor performance tem a hora de classificar, e é aquele que tem menor erro de todos

3. Sigmoid, quando utilizando os atributos, só consegue determinar a classe 1


Possíveis melhorias a ser feita:
Um maior quantidade de valores dentro de Grid Search, para encontrar ainda os melhores atributos para cada modelo