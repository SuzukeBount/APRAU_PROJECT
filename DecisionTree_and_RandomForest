Para as decision trees e random forest, numa primeira instância, foi pedido o mesmo tipo de análise

1. Decision tree

1.1. Utilizar o modelo de classificação para diferenciar as classes e construir um tree 

Foi testado um modelo sem atributos extra, para a construção da primeira decision tree
Sendo este o resultado obtido

Accuracy: 89.24050632911393 
Train Accuracy: 100.0

Classification Report:
               precision    recall  f1-score   support

           0       0.86      0.82      0.84       421
           1       0.90      0.93      0.91       584
           2       0.94      0.93      0.94       259

    accuracy                           0.89      1264
   macro avg       0.90      0.89      0.89      1264
weighted avg       0.89      0.89      0.89      1264


Confusion Matrix 
[[344  62  15]
 [ 41 542   1]
 [ 17   0 242]]

Error Rate: 0.10759493670886076
Mean Squared Error (MSE): 0.1835
Mean Absolute Error (MAE): 0.1329
Root Mean Squared Error (RMSE): 0.4284
0.8924050632911392
Log Loss: 3.8781
ROC AUC: 0.9173

O que podemos analissar de isto é:
- O modelo tem um alto teor de accuracy perante o dataset
- O modelo tem 100% de train accuracy, indicando que tem uma grande diferença entre train e test, levando a overfitting
- O modelo tem um erro pequeno
- O modelo consegue classificar com maior certidão a classe 2




1.2. Utilizar Grid Search para encontrar os melhores atributos para cada modelo
Utilizando o método de Grid Search estes foram os melhores valores para o modelo de decision tree
{'ccp_alpha': 0.0, 'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}
Embora este tenha sido o resultado do Grid Search, não iremos utilizar todos estes valores, devido que no max_depth e no max_leaf_nodes, se for None, irá existir overfitting
Resultando em provar diferentes valores para o modelo, chegamos a conclussão que, para o max_depth, é 50 e para o max_leaf_nodes é 100



1.3 Utilizar os atributos resultantes do Grid Search
Accuracy: 89.47784810126582 
Train Accuracy: 95.7259158751696

Classification Report:
               precision    recall  f1-score   support

           0       0.91      0.76      0.83       421
           1       0.87      0.96      0.91       584
           2       0.93      0.97      0.95       259

    accuracy                           0.89      1264
   macro avg       0.91      0.90      0.90      1264
weighted avg       0.90      0.89      0.89      1264


Confusion Matrix 
[[318  85  18]
 [ 23 561   0]
 [  7   0 252]]

Error Rate: 0.10522151898734178
Mean Squared Error (MSE): 0.1646
Mean Absolute Error (MAE): 0.1250
Root Mean Squared Error (RMSE): 0.4057
0.8947784810126582
Log Loss: 1.5110
ROC AUC: 0.9427

Analissando:
- O modelo não perdeu accuracy
- O modelo reduziu o overfitting, existindo ainda um certo overfitting, mas com um valor muito menor
- A nível de f1 e precision, o modelo melhora em compração com o primeiro
- Para a classe 1 e 2 o modelo melhora significativamente com a redução de erro
- O modelo tem valores de erro menores
- O modelo presenta melhores valores de ROC AUC e de Log Loss

Em conclussão, o modelo de decision trees, ao ter os atributos corretos, melhora significativamente ao longo de todos os atributos de validação, levando a um menor nível de overfitting, e possibilitando
Um análise mais correto



2. Random Forest

2.1. Utilizar o modelo de classificação para diferenciar as classes e construir uma tree 

Accuracy: 92.16772151898735 
Train Accuracy: 100.0

Classification Report:
               precision    recall  f1-score   support

           0       0.94      0.81      0.87       421
           1       0.90      0.98      0.93       584
           2       0.95      0.97      0.96       259

    accuracy                           0.92      1264
   macro avg       0.93      0.92      0.92      1264
weighted avg       0.92      0.92      0.92      1264


Confusion Matrix:
 [[343  66  12]
 [ 14 570   0]
 [  7   0 252]]
Log Loss: 0.2630
ROC AUC: 0.9827
0.9216772151898734
Error Rate: 0.07832278481012658
Mean Squared Error (MSE): 0.1234
Mean Absolute Error (MAE): 0.0934
Root Mean Squared Error (RMSE): 0.3513

Analissando:
- Tem uma accuracy muit alta de 92%
- Tem um train accuracy de 100% indicando overfitting
- Precision, recall e f1-score são fortes na classe 2 em comparação com o resto
- A matriz de confussão apresenta melhores valores para a classe 1 e 2, sendo a 0 a mais perjudicada
- Log loss e o ROC AUC têm valores positivos
- O teor de erro que tem o modelo é baixo

2.2. Utilizar Grid Search para encontrar os melhores atributos para cada modelo
Utilizando o método de Grid Search estes foram os melhores valores para o modelo de Random Forest
{'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': 42, 'verbose': 0}
Embora este tenha sido o resultado do Grid Search, não iremos utilizar todos estes valores, devido que no max_depth e no max_leaf_nodes, se for None, irá existir overfitting
Resultando em provar diferentes valores para o modelo, chegamos a conclussão que, para o max_depth, é 50 e para o max_leaf_nodes é 100



2.3 Utilizar os atributos resultantes do Grid Search
Accuracy: 92.40506329113924 
Train Accuracy: 97.96472184531886

Classification Report:
               precision    recall  f1-score   support

           0       0.95      0.81      0.88       421
           1       0.90      0.98      0.94       584
           2       0.94      0.99      0.97       259

    accuracy                           0.92      1264
   macro avg       0.93      0.93      0.93      1264
weighted avg       0.93      0.92      0.92      1264


Confusion Matrix:
 [[342  64  15]
 [ 14 570   0]
 [  3   0 256]]
Log Loss: 0.2346
ROC AUC: 0.9797
0.9240506329113924
Error Rate: 0.0759493670886076
Mean Squared Error (MSE): 0.1187
Mean Absolute Error (MAE): 0.0902
Root Mean Squared Error (RMSE): 0.3445

Analisando:
- O modelo tem uma melhor accuracy
- O modelo apresenta menos overfitting em comparação 
- Em termos de precision, recall e f1-score são muito idênticos entre os modelos, tendo o modelo 2, uma pequena vantagem, embora pouco notável
- A matriz de confusão no modelo 2, na classe 2 e 1 melhora, mas não na classe 0
- Log Loss e ROC AUC, apresenta melhores valores no modelo 2
- O teor de erro do modelo 2 é menor

Em conclusão, o modelo utilizando os atributos específicados, tem em geral, uma maior performance em comparação a não utilizar
Ou seja, conseguimos melhorar o modelo para poder ser utilizado, sem ter tanto overfitting

2.4 Lista ordenada com os atributos mais importantes
Estes são as features com maior importância, ordenadas

Altitude                              0.629886
Id                                    0.140657
Horizontal_Distance_To_Roadways       0.056539
Horizontal_Distance_To_Fire_Points    0.046913
Horizontal_Distance_To_Water          0.034146
Slope_Orientation                     0.021079
Shadow_Index_12h                      0.020796
Shadow_Index_9h                       0.018765
Shadow_Index_15h                      0.012110
Slope                                 0.009665
Wind_Exposure_Level                   0.009444


2.5 Correlação entre o análise inicial da parte 1 com o ponto anterior

task 2

Altitude                              0.47
Id                                    0.24
Horizontal_Distance_To_Roadways       0.10
Horizontal_Distance_To_Fire_Points    0.08
Horizontal_Distance_To_Water          0.08
Slope_Orientation                     0
Shadow_Index_12h                      0.06
Shadow_Index_9h                       0.06
Shadow_Index_15h                      0.07
Slope                                 0.05
Wind_Exposure_Level                   0.01

task 4

Features eliminadas
CANOPY_DENSITY
RAINFALL_SUMMER
RAINFALL_WINTER
VERTICAL_DISTANCE_TO_WATER
SOIL_TYPE
WILDERNESS_AREA


Como se pode comprobar, no análise da task 2, existem algumas correalações existentes, que podiam ser eliminadas, pela baixa correlação que estas têm no com a variável objetivo
Contudo, a hora de estar na task 4, e de ir eliminando features com pouca correlação, conseguimos determinar, que se essas features fossem eliminadas, o dataset não iria ficar com melhor performance

Comparando a parte de random forest com o resto das tasks, podemos verificar, que sim, essas features com pouca correlação, irão ter uma menor importância a hora de contruir a tree
