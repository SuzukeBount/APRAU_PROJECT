Para as decision trees e random forest, numa primeira instância, foi pedido o mesmo tipo de análise

1. Decision tree

1.1. Utilizar o modelo de classificação para diferenciar as classes e construir um tree 

Foi testado um modelo sem atributos extra, para a construção da primeira decision tree
Sendo este o resultado obtido

Accuracy: 89.24050632911393 
Train Accuracy: 100.0

Classification Report:
               precision    recall  f1-score   support

           0       0.86      0.82      0.84       421
           1       0.90      0.93      0.91       584
           2       0.94      0.93      0.94       259

    accuracy                           0.89      1264
   macro avg       0.90      0.89      0.89      1264
weighted avg       0.89      0.89      0.89      1264


Confusion Matrix 
[[344  62  15]
 [ 41 542   1]
 [ 17   0 242]]

Error Rate: 0.10759493670886076
Mean Squared Error (MSE): 0.1835
Mean Absolute Error (MAE): 0.1329
Root Mean Squared Error (RMSE): 0.4284
0.8924050632911392
Log Loss: 3.8781
ROC AUC: 0.9173

O que podemos analissar de isto é:
- O modelo tem um alto teor de accuracy perante o dataset
- O modelo tem 100% de train accuracy, indicando que tem uma grande diferença entre train e test, levando a overfitting
- O modelo tem um erro pequeno
- O modelo consegue classificar com maior certidão a classe 2




1.2. Utilizar Grid Search para encontrar os melhores atributos para cada modelo
Utilizando o método de Grid Search estes foram os melhores valores para o modelo de decision tree
{'ccp_alpha': 0.0, 'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}
Embora este tenha sido o resultado do Grid Search, não iremos utilizar todos estes valores, devido que no max_depth e no max_leaf_nodes, se for None, irá existir overfitting
Resultando em provar diferentes valores para o modelo, chegamos a conclussão que, para o max_depth, é 50 e para o max_leaf_nodes é 100



1.3 Utilizar os atributos resultantes do Grid Search
Accuracy: 89.47784810126582 
Train Accuracy: 95.7259158751696

Classification Report:
               precision    recall  f1-score   support

           0       0.91      0.76      0.83       421
           1       0.87      0.96      0.91       584
           2       0.93      0.97      0.95       259

    accuracy                           0.89      1264
   macro avg       0.91      0.90      0.90      1264
weighted avg       0.90      0.89      0.89      1264


Confusion Matrix 
[[318  85  18]
 [ 23 561   0]
 [  7   0 252]]

Error Rate: 0.10522151898734178
Mean Squared Error (MSE): 0.1646
Mean Absolute Error (MAE): 0.1250
Root Mean Squared Error (RMSE): 0.4057
0.8947784810126582
Log Loss: 1.5110
ROC AUC: 0.9427

Analissando:
- O modelo não perdeu accuracy
- O modelo reduziu o overfitting, existindo ainda um certo overfitting, mas com um valor muito menor
- A nível de f1 e precision, o modelo melhora em compração com o primeiro
- Para a classe 1 e 2 o modelo melhora significativamente com a redução de erro
- O modelo tem valores de erro menores
- O modelo presenta melhores valores de ROC AUC e de Log Loss

Em conclussão, o modelo de decision trees, ao ter os atributos corretos, melhora significativamente ao longo de todos os atributos de validação, levando a um menor nível de overfitting, e possibilitando
Um análise mais correto



2. Random Forest

1.1. Utilizar o modelo de classificação para diferenciar as classes e construir uma tree 

Accuracy: 92.16772151898735 
Train Accuracy: 100.0

Classification Report:
               precision    recall  f1-score   support

           0       0.94      0.81      0.87       421
           1       0.90      0.98      0.93       584
           2       0.95      0.97      0.96       259

    accuracy                           0.92      1264
   macro avg       0.93      0.92      0.92      1264
weighted avg       0.92      0.92      0.92      1264


Confusion Matrix:
 [[343  66  12]
 [ 14 570   0]
 [  7   0 252]]
Log Loss: 0.2630
ROC AUC: 0.9827
0.9216772151898734
Error Rate: 0.07832278481012658
Mean Squared Error (MSE): 0.1234
Mean Absolute Error (MAE): 0.0934
Root Mean Squared Error (RMSE): 0.3513

Analissando:
- Tem uma accuracy muit alta de 92%
- Tem um train accuracy de 100% indicando overfitting
- Precision, recall e f1-score são fortes na classe 2 em comparação com o resto
- A matriz de confussão apresenta melhores valores para a classe 1 e 2, sendo a 0 a mais perjudicada
- Log loss e o ROC AUC têm valores positivos
- O teor de erro que tem o modelo é baixo

1.2. Utilizar Grid Search para encontrar os melhores atributos para cada modelo


1.3 Utilizar os atributos resultantes do Grid Search


1.4 Lista ordenada com os atributos mais importantes


1.5 Correlação entre o análise inicial da parte 1 com o ponto anterior